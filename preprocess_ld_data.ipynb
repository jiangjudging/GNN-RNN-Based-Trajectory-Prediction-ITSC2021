{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch,shutil, random, os\n",
    "import os.path as osp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from plot_helper import find_files,create_new_dir\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "给每个bag设立一个单独的文件夹,方便后面测试使用\n",
    "'''\n",
    "bag_dirpath = '/home/jiang/trajectory_pred/ld_dataset/Dataset_for_Master_Thesis'\n",
    "\n",
    "def move_bag_to_dir(bag_dirpath):\n",
    "    bags = find_files(bag_dirpath)\n",
    "    for b in bags:\n",
    "        bag_name = b.split('/')[-1][:-4]\n",
    "        dst_dir = create_new_dir(bag_dirpath,bag_name)\n",
    "        dst_path = osp.join(dst_dir,b.split('/')[-1])\n",
    "        shutil.move(b, dst_path)\n",
    "        \n",
    "# move_bag_to_dir(bag_dirpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "给每个bag都生成对应的obj以及ego.csv\n",
    "'''\n",
    "import subprocess\n",
    "from tqdm import tqdm\n",
    "bag2csv_path = \"/home/jiang/VW/toolchain/compass_script/tools/bag2csv\"\n",
    "def run_bag2csv(_cwd, bag_path, output_dir):\n",
    "    subprocess.check_output(['./bag2csv', bag_path, output_dir], cwd=_cwd, stderr=subprocess.STDOUT)\n",
    "\n",
    "\n",
    "def run_bag2csv_all(_cwd, bag_dir):\n",
    "    bags = find_files(bag_dir,recursive=True)\n",
    "    for b in tqdm(bags):\n",
    "        out_path = osp.dirname(b)\n",
    "        run_bag2csv(_cwd, b, out_path)\n",
    "\n",
    "# run_bag2csv_all(bag2csv_path,bag_dirpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delete: The obj id:   2 has min_dist 147.22 and max_dist 149.54\n",
      "delete: The obj id:   4 has min_dist 117.66 and max_dist 154.28\n",
      "delete: The obj id:   6 has min_dist 111.45 and max_dist 134.72\n",
      "delete: The obj id:  14 has min_dist  -9.58 and max_dist  -0.83\n",
      "delete: The obj id:  20 has min_dist 129.00 and max_dist 133.49\n",
      "delete: The obj id:  22 has min_dist 145.02 and max_dist 146.17\n",
      "delete: The obj id:  24 has min_dist 126.35 and max_dist 126.35\n",
      "delete: The obj id:  26 has min_dist 121.01 and max_dist 128.92\n",
      "delete: The obj id:  28 has min_dist 142.20 and max_dist 144.67\n",
      "delete: The obj id:  32 has min_dist 110.21 and max_dist 114.33\n",
      "delete: The obj id:  36 has min_dist 161.59 and max_dist 184.04\n",
      "delete: The obj id:  38 has min_dist 143.79 and max_dist 144.32\n",
      "delete: The obj id:  40 has min_dist 138.76 and max_dist 142.27\n",
      "delete: The obj id:  84 has min_dist 149.13 and max_dist 203.62\n",
      "delete: The obj id:  94 has min_dist 157.11 and max_dist 203.51\n",
      "delete: The obj id:  96 has min_dist 181.28 and max_dist 181.81\n",
      "delete: The obj id:  98 has min_dist 180.48 and max_dist 180.83\n",
      "delete: The obj id: 100 has min_dist 181.07 and max_dist 236.92\n",
      "delete: The obj id: 102 has min_dist 119.35 and max_dist 205.23\n",
      "delete: The obj id: 128 has min_dist 196.72 and max_dist 214.08\n",
      "delete: The obj id: 132 has min_dist 207.32 and max_dist 233.20\n",
      "delete: The obj id: 140 has min_dist 231.96 and max_dist 240.61\n",
      "delete: The obj id: 144 has min_dist 156.89 and max_dist 178.67\n",
      "delete: The obj id: 146 has min_dist 214.19 and max_dist 218.00\n",
      "delete: The obj id: 152 has min_dist 180.54 and max_dist 181.51\n",
      "delete: The obj id: 154 has min_dist 164.98 and max_dist 176.43\n",
      "delete: The obj id: 156 has min_dist 124.40 and max_dist 140.39\n",
      "delete: The obj id: 158 has min_dist 116.54 and max_dist 119.35\n",
      "delete: The obj id: 160 has min_dist 143.67 and max_dist 155.21\n",
      "delete: The obj id: 164 has min_dist 118.22 and max_dist 122.10\n",
      "delete: The obj id: 166 has min_dist 163.10 and max_dist 168.24\n",
      "delete: The obj id: 170 has min_dist 222.55 and max_dist 231.78\n",
      "delete: The obj id: 174 has min_dist  98.05 and max_dist 107.37\n",
      "delete: The obj id: 178 has min_dist 227.57 and max_dist 236.46\n",
      "delete: The obj id:  43 has min_dist 167.50 and max_dist 167.50\n",
      "delete: The obj id:  45 has min_dist 161.78 and max_dist 161.78\n",
      "delete: The obj id: 190 has min_dist 144.14 and max_dist 165.87\n",
      "delete: The obj id: 192 has min_dist 227.70 and max_dist 241.69\n",
      "delete: The obj id: 230 has min_dist 114.35 and max_dist 115.90\n",
      "delete: The obj id: 240 has min_dist 227.67 and max_dist 240.86\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "1. 删除没有在0-100m出现过的obj\n",
    "'''\n",
    "obj_csv = '/home/jiang/trajectory_pred/ld_dataset/Dataset_for_Master_Thesis/LIDAR_LJ02766_20210916_054052_G260-PDX-006-001-052_000000-000012_LD_final__OD_MERGE_OPP/LIDAR_LJ02766_20210916_054052_G260-PDX-006-001-052_000000-000012_LD_final__OD_MERGE_OPP_obj.csv'\n",
    "ego_csv = '/home/jiang/trajectory_pred/ld_dataset/Dataset_for_Master_Thesis/LIDAR_LJ02766_20210916_054052_G260-PDX-006-001-052_000000-000012_LD_final__OD_MERGE_OPP/LIDAR_LJ02766_20210916_054052_G260-PDX-006-001-052_000000-000012_LD_final__OD_MERGE_OPP_ego.csv'\n",
    "\n",
    "obj_df = pd.read_csv(obj_csv)\n",
    "ego_df = pd.read_csv(ego_csv)\n",
    "\n",
    "def del_obj_out_range(df,min_dist=0,max_dist=90):\n",
    "    '''\n",
    "    删除最远距离小于min_dist或者最小距离大于max_dist的obj\n",
    "    '''\n",
    "    # src_obj_id = df['obj_id'].unique()\n",
    "    src_obj_id = df['object.id'].unique()\n",
    "    ret_df = pd.DataFrame()\n",
    "    \n",
    "    for obj_id in src_obj_id:\n",
    "        # obj_id_df = df[df.obj_id == obj_id]\n",
    "        # _min_dist = min(obj_id_df['LocalX'])\n",
    "        # _max_dist = max(obj_id_df['LocalX'])\n",
    "        \n",
    "        obj_id_df = df[df['object.id'] == obj_id]\n",
    "        _min_dist = min(obj_id_df['pose.position.x'])\n",
    "        _max_dist = max(obj_id_df['pose.position.x'])\n",
    "        \n",
    "        if _min_dist > max_dist or _max_dist < min_dist:\n",
    "            print(f\"delete: The obj id: {obj_id:3} has min_dist {_min_dist:6,.2f} and max_dist {_max_dist:6,.2f}\")\n",
    "        else:\n",
    "            ret_df = ret_df.append(obj_id_df)\n",
    "    ret_df.sort_values(by=['object list No.','object.id'],inplace=True)\n",
    "    return ret_df\n",
    "\n",
    "del1_obj_df = del_obj_out_range(obj_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delete: The obj id:   9 has duration   0.50s.\n",
      "delete: The obj id:  10 has duration   1.30s.\n",
      "delete: The obj id:  16 has duration   0.35s.\n",
      "delete: The obj id:  30 has duration   0.25s.\n",
      "delete: The obj id:  48 has duration   0.65s.\n",
      "delete: The obj id:  50 has duration   0.55s.\n",
      "delete: The obj id:  56 has duration   2.20s.\n",
      "delete: The obj id:  57 has duration   0.25s.\n",
      "delete: The obj id: 112 has duration   2.40s.\n",
      "delete: The obj id: 206 has duration   1.90s.\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "1. 删除生命周期小于3s的obj-->\n",
    "'''\n",
    "\n",
    "def del_obj_life_less(df,duration=3):\n",
    "    '''\n",
    "    删除生命周期短于duration的obj\n",
    "    '''\n",
    "    # src_obj_id = df['obj_id'].unique()\n",
    "    src_obj_id = df['object.id'].unique()\n",
    "    ret_df = pd.DataFrame()\n",
    "    \n",
    "    for obj_id in src_obj_id:\n",
    "        # obj_id_df = df[df.obj_id == obj_id]\n",
    "        obj_id_df = df[df['object.id'] == obj_id]\n",
    "        # _duration = max(obj_id_df['timestamp']) - min(obj_id_df['timestamp'])\n",
    "        _duration = max(obj_id_df['bag timestamp']) - min(obj_id_df['bag timestamp'])\n",
    "        if _duration < duration:\n",
    "            print(f\"delete: The obj id: {obj_id:3} has duration {_duration:6,.2f}s.\")\n",
    "        else:\n",
    "            ret_df = ret_df.append(obj_id_df)\n",
    "    # ret_df.sort_values(by=['frame_id','obj_id'],inplace=True)\n",
    "    ret_df.sort_values(by=['object list No.','object.id'],inplace=True)\n",
    "    return ret_df\n",
    "\n",
    "del2_obj_df = del_obj_life_less(del1_obj_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The obj id:  11 has gap of 0.35s ( 7 frame) at  2021-09-16 05:42:12.077146 (1631770932.077).\n",
      "The obj id:  54 has gap of 0.35s ( 7 frame) at  2021-09-16 05:41:45.877400 (1631770905.877).\n",
      "defaultdict(<class 'list'>, {11: [[1582, 1589]], 54: [[1058, 1065]]})\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "检查是否有重复id\n",
    "'''\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "def dup_id_check(df,gap=0.3):\n",
    "    '''\n",
    "    检查是否存在id的间隔大于gap的值\n",
    "    '''\n",
    "    # src_obj_id = df['obj_id'].unique()\n",
    "    src_obj_id = df['object.id'].unique()\n",
    "    ret_df = pd.DataFrame()\n",
    "    large_gap = defaultdict(list)\n",
    "    for obj_id in src_obj_id:\n",
    "        # obj_id_df = df[df.obj_id == obj_id]\n",
    "        # ts = obj_id_df['timestamp'].to_numpy()\n",
    "        # _date = obj_id_df['date'].to_numpy()\n",
    "        obj_id_df = df[df['object.id'] == obj_id]\n",
    "        ts = obj_id_df['bag timestamp'].to_numpy()\n",
    "        f = obj_id_df['object list No.'].to_numpy()\n",
    "        # _date = obj_id_df['date'].to_numpy()\n",
    "        _gap = ts[1:] - ts[:-1]\n",
    "        idxs = np.argwhere(_gap>gap)\n",
    "        if len(idxs)>0:\n",
    "            for i in idxs:\n",
    "                t1 = ts[i[0]]\n",
    "                t2 = ts[i[0]+1]\n",
    "                f1,f2 = f[i[0]],f[i[0]+1]\n",
    "                large_gap[obj_id].append([f1,f2])\n",
    "                print(f\"The obj id: {obj_id:3} has gap of {t2-t1:4,.2f}s ({f2-f1:2} frame) at  {datetime.utcfromtimestamp(t1)} ({t1:.3f}).\")\n",
    "    return large_gap\n",
    "large_gap = dup_id_check(del2_obj_df)\n",
    "print(large_gap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "检查出现重复id的情况\n",
    "通过用ld_editor查看：\n",
    "11以及54-->漏标了6帧\n",
    "'''\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "把漏标的给插值上去，只用插值：'pose.position.x','pose.position.y'\n",
    "直接继承：'object.id'，'class_label_pred'，'dimension_x', 'dimension_y','yaw'\n",
    "'''\n",
    "\n",
    "def linear_interpol(df,gap_dict):\n",
    "    '''\n",
    "    把gap值较大的id的obj进行线性插值\n",
    "    '''\n",
    "    for obj_id,gap_list in gap_dict.items():\n",
    "        obj_id_df = df[df['object.id'] == obj_id]\n",
    "        for gap in gap_list:\n",
    "            start_frame_id,end_frame_id = gap[0],gap[1]\n",
    "            gap_frames = end_frame_id - start_frame_id -1 \n",
    "            \n",
    "            start_frame,end_frame = obj_id_df[obj_id_df['object list No.']==start_frame_id],obj_id_df[obj_id_df['object list No.']==end_frame_id]\n",
    "            start_x,end_x = start_frame['pose.position.x'],end_frame['pose.position.x']\n",
    "            start_y,end_y = start_frame['pose.position.y'],end_frame['pose.position.y']\n",
    "            start_t,end_t = start_frame['bag timestamp'],end_frame['bag timestamp']\n",
    "            \n",
    "            x  = np.linspace(start_x,end_x,num=gap_frames+2)[1:-1]\n",
    "            y = np.linspace(start_y,end_y,num=gap_frames+2)[1:-1]\n",
    "            t = np.linspace(start_t,end_t,num=gap_frames+2)[1:-1]\n",
    "            gap_frame_ids = [i for i in range(start_frame_id+1,end_frame_id)]\n",
    "            for _x,_y,_t,frame_id in zip(x,y,t,gap_frame_ids):\n",
    "                new_frame = start_frame.copy()\n",
    "                new_frame['pose.position.x'] = _x\n",
    "                new_frame['pose.position.y'] = _y\n",
    "                new_frame['object list No.'] = frame_id\n",
    "                new_frame['bag timestamp'] = _t\n",
    "                new_frame['header timestamp'] = _t\n",
    "                df = df.append(new_frame)\n",
    "    df.sort_values(by=['object list No.','object.id'],inplace=True)\n",
    "    return df\n",
    "\n",
    "interp_df = linear_interpol(del2_obj_df,large_gap)\n",
    "interp_df.to_csv('/home/jiang/trajectory_pred/ld_dataset/Dataset_for_Master_Thesis/LIDAR_LJ02766_20210916_054052_G260-PDX-006-001-052_000000-000012_LD_final__OD_MERGE_OPP/obj_filter_interp.csv',index = False)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "把obj_df以及ego_df合并起来，并且算出GlobalX，以及GlobalY\n",
    "选择其中一个bag作为测试\n",
    "'''\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "\n",
    "def cal_globalXY(merge_df):\n",
    "    '''\n",
    "    Calculate global X and Y\n",
    "    '''\n",
    "    frame_id_set = merge_df['frame_id'].unique()\n",
    "    for frame_id in frame_id_set:\n",
    "        frame_id_mask = (merge_df['frame_id']==frame_id)\n",
    "        obj_id_mask = merge_df['obj_id'] != 0\n",
    "        \n",
    "        ego_global_x,ego_global_y = merge_df[frame_id_mask].iloc[0]['GlobalX'],merge_df[frame_id_mask].iloc[0]['GlobalY']\n",
    "        merge_df.loc[frame_id_mask & obj_id_mask,['GlobalX']] = ego_global_x\n",
    "        merge_df.loc[frame_id_mask & obj_id_mask,['GlobalY']] = ego_global_y\n",
    "        \n",
    "    merge_df.loc[:,'GlobalX'] += merge_df['LocalX']\n",
    "    merge_df.loc[:,'GlobalY'] += merge_df['LocalY']\n",
    "    return merge_df\n",
    "    \n",
    "\n",
    "def merge_obj_ego(obj_df,ego_df):\n",
    "    '''\n",
    "    把obj_df以及ego_df合并起来，并且算出GlobalX，以及GlobalY\n",
    "    '''\n",
    "    \n",
    "    # 取出需要的列\n",
    "    obj_df = obj_df[['object list No.','bag timestamp','object.id','class_label_pred','pose.position.x','pose.position.y']].copy()\n",
    "    ego_df = ego_df[['frame seq','bag timestamp','position x','position y']].copy()\n",
    "\n",
    "    # 给ego_df的列重命名以及赋初值\n",
    "    ego_df.rename(columns={'frame seq':'frame_id','bag timestamp':'timestamp','position x':'GlobalX','position y':'GlobalY'},inplace=True)\n",
    "    ego_df['class'] = 'Car'\n",
    "    ego_df.loc[:,['LocalX','LocalY','obj_id']] = 0\n",
    "\n",
    "    # 给obj_df的列重命名以及赋初值\n",
    "    obj_df.rename(columns={'object list No.':'frame_id','bag timestamp':'timestamp','object.id':'obj_id','class_label_pred':'class','pose.position.x':'LocalX','pose.position.y':'LocalY'},inplace=True)\n",
    "    obj_df.loc[:,['GlobalX','GlobalY']] = 0\n",
    "\n",
    "    # 把两个df concate起来，并且按照frame_id和obj_id排序，列重新排列,增加一个可读时间\n",
    "    merge_df = pd.concat([ego_df,obj_df])\n",
    "    merge_df.sort_values(by=['frame_id','obj_id'],inplace=True)\n",
    "    merge_df = merge_df[['frame_id','timestamp','obj_id','class','LocalX','LocalY','GlobalX','GlobalY']]\n",
    "    # merge_df['date'] = pd.to_datetime(merge_df['timestamp'],unit='s').dt.tz_localize('Europe/Berlin')\n",
    "    merge_df['date'] = pd.to_datetime(merge_df['timestamp'],unit='s')\n",
    "    merge_df = merge_df[['frame_id','date','timestamp','obj_id','class','LocalX','LocalY','GlobalX','GlobalY']]\n",
    "    # 计算golbal x y\n",
    "    merge_df = cal_globalXY(merge_df)\n",
    "    return merge_df\n",
    "    \n",
    "merge_df = merge_obj_ego(obj_df,ego_df)\n",
    "\n",
    "merge_df.to_csv('/home/jiang/trajectory_pred/ld_dataset/Dataset_for_Master_Thesis/LIDAR_LJ02766_20210916_054052_G260-PDX-006-001-052_000000-000012_LD_final__OD_MERGE_OPP/merge.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "现在的数据是20Hz的，降采样为10Hz\n",
    "'''\n",
    "def down_sample(df,r=2):\n",
    "    src_frame_id = df['frame_id'].unique()\n",
    "    dst_frame_id = np.arange(start=0,stop=len(src_frame_id),step=r)\n",
    "    \n",
    "    ret_df = pd.DataFrame()\n",
    "    for idx,frame_id in enumerate(dst_frame_id):\n",
    "        frame_id_df = df[df['frame_id']==frame_id].copy()\n",
    "        frame_id_df.loc[:,'frame_id'] = idx\n",
    "        ret_df = ret_df.append(frame_id_df)\n",
    "    return ret_df\n",
    "\n",
    "merge_ds_df = down_sample(merge_df)\n",
    "merge_ds_df.to_csv('/home/jiang/trajectory_pred/ld_dataset/Dataset_for_Master_Thesis/LIDAR_LJ02766_20210916_054052_G260-PDX-006-001-052_000000-000012_LD_final__OD_MERGE_OPP/merge_10hz.csv',index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3c942d3571ed5f04fca520b5ade2ad670b64a6a2c7541b299cf29b498855d4f8"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit ('GRTP': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
